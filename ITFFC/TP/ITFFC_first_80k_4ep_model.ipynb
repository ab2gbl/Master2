{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ab2gbl/Master2/blob/main/ITFFC/TP/ITFFC_first_80k_4ep_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nAZC1qYNcPp"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/liamdugan/human-detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "trJr1IpyZdct"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVoP28LJCz28",
        "outputId": "d3463ae9-b1bd-41c3-dc9d-64bbfef0db35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.6)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROFT dataset"
      ],
      "metadata": {
        "id": "nTBOYhV8thl5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L0V6KMCWPyCr"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/Master2/ITFFC/roft.csv ./roft.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGRBBoTDbEsg",
        "outputId": "3e00f49c-39a1-470f-bc38-998c9d43b25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               date      model  dataset  annotator group  \\\n",
            "0  2021-08-31 17:11:39.095000+00:00  finetuned  Recipes       1666     A   \n",
            "1  2021-09-06 21:54:48.912000+00:00  finetuned  Recipes       1666     A   \n",
            "2  2021-09-06 21:55:07.069000+00:00  finetuned  Recipes       1666     A   \n",
            "3  2021-09-06 21:58:44.944000+00:00  finetuned  Recipes       1666     A   \n",
            "4  2021-09-06 21:59:16.230000+00:00  finetuned  Recipes       1666     A   \n",
            "\n",
            "   dec_strat_value  predicted_boundary_index  true_boundary_index  points  \\\n",
            "0              0.4                         0                    2       0   \n",
            "1              0.4                         8                    8       5   \n",
            "2              0.4                         0                    7       0   \n",
            "3              0.4                         1                    7       0   \n",
            "4              0.4                         1                    2       0   \n",
            "\n",
            "                    reason  prompt  \\\n",
            "0  ['9123971792800820313']   13803   \n",
            "1           ['irrelevant']   20719   \n",
            "2           ['irrelevant']   20365   \n",
            "3   ['326860638652886185']   20240   \n",
            "4           ['repetition']   13888   \n",
            "\n",
            "                                         prompt_body  generation  \\\n",
            "0  HOW TO MAKE: Baby Shell Pasta Salad With Kalam...       22877   \n",
            "1  HOW TO MAKE: Nest Cookies\\nIngredients:\\n1 12 ...       26444   \n",
            "2  HOW TO MAKE: Pink Lemonade Cupcakes\\nIngredien...       26089   \n",
            "3  HOW TO MAKE: Beef Stroganaff\\nIngredients:\\n1 ...       25963   \n",
            "4  HOW TO MAKE: One-Pan Creamy Chicken and Veggie...       23225   \n",
            "\n",
            "                                            gen_body  recipe_familiarity  \\\n",
            "0  Meanwhile, combine all dressing ingredients in...                   2   \n",
            "1  Photograph by fans blistering bens down!_SEP_F...                   2   \n",
            "2  Fill prepared pans two-thirds full._SEP_Bake f...                   2   \n",
            "3  I have added some green peppers, red peppers, ...                   2   \n",
            "4  Add frozen veggies and pasta._SEP_Pour in chic...                   2   \n",
            "\n",
            "   news_familiarity  stories_familiarity  gen_familiarity native_speaker  \\\n",
            "0                 3                    5                2            Yes   \n",
            "1                 3                    5                2            Yes   \n",
            "2                 3                    5                2            Yes   \n",
            "3                 3                    5                2            Yes   \n",
            "4                 3                    5                2            Yes   \n",
            "\n",
            "  read_guide  \n",
            "0        NaN  \n",
            "1        NaN  \n",
            "2        NaN  \n",
            "3        NaN  \n",
            "4        NaN  \n",
            "date                           0\n",
            "model                          0\n",
            "dataset                        0\n",
            "annotator                      0\n",
            "group                          0\n",
            "dec_strat_value                0\n",
            "predicted_boundary_index       0\n",
            "true_boundary_index            0\n",
            "points                         0\n",
            "reason                         0\n",
            "prompt                         0\n",
            "prompt_body                    0\n",
            "generation                     0\n",
            "gen_body                    3397\n",
            "recipe_familiarity             0\n",
            "news_familiarity               0\n",
            "stories_familiarity            0\n",
            "gen_familiarity                0\n",
            "native_speaker                 0\n",
            "read_guide                  6089\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the RoFT dataset\n",
        "roft_df = pd.read_csv(\"roft.csv\")\n",
        "\n",
        "# Inspect the first few rows\n",
        "print(roft_df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(roft_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TnfBLf53bWRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46440f98-c339-4369-f492-a9ef4276c6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-bf88d409cc97>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  roft_df[\"label\"] = roft_df[\"model\"].apply(lambda x: 1 if x != \"baseline\" else 0)\n"
          ]
        }
      ],
      "source": [
        "# Drop rows where `gen_body` is NaN\n",
        "roft_df = roft_df.dropna(subset=[\"gen_body\"])\n",
        "\n",
        "# Create a binary label column: AI-generated (1) or Human-written (0)\n",
        "roft_df[\"label\"] = roft_df[\"model\"].apply(lambda x: 1 if x != \"baseline\" else 0)\n",
        "\n",
        "# Select only the relevant columns\n",
        "roft_df = roft_df[[\"gen_body\", \"label\"]]\n",
        "\n",
        "roft_df.rename(columns={'gen_body': 'text'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km3RT_eiHhBA",
        "outputId": "edf98278-d4c4-449d-c522-fd6792149331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with label=0: 196\n",
            "Number of rows with label=1: 24021\n"
          ]
        }
      ],
      "source": [
        "num_rows_label_0 = roft_df[roft_df[\"label\"] == 0].shape[0]\n",
        "num_rows_label_1 = roft_df[roft_df[\"label\"] == 1].shape[0]\n",
        "\n",
        "\n",
        "print(f\"Number of rows with label=0: {num_rows_label_0}\")\n",
        "print(f\"Number of rows with label=1: {num_rows_label_1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmented data for LLM - Detect AI Generated Text"
      ],
      "metadata": {
        "id": "tZdQZxqQtn19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/jdragonxherrera/augmented-data-for-llm-detect-ai-generated-text\")\n",
        "# 9aba4703ac130612b1bc4c2d83ed8627\n",
        "#https://www.kaggle.com/datasets/ratthachat/writing-prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa7ph5Cisp8W",
        "outputId": "73072af0-ee23-4a09-a2ca-46dd9f821465"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: abdessamiguebli\n",
            "Your Kaggle Key: 路路路路路路路路路路\n",
            "Dataset URL: https://www.kaggle.com/datasets/jdragonxherrera/augmented-data-for-llm-detect-ai-generated-text\n",
            "Downloading augmented-data-for-llm-detect-ai-generated-text.zip to ./augmented-data-for-llm-detect-ai-generated-text\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 314M/314M [00:03<00:00, 100MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aug_train = pd.read_csv('/content/augmented-data-for-llm-detect-ai-generated-text/final_train.csv')\n",
        "aug_test = pd.read_csv('/content/augmented-data-for-llm-detect-ai-generated-text/final_test.csv')\n"
      ],
      "metadata": {
        "id": "ibgaNQTu6ZbT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmvDbOucs5lf",
        "outputId": "323b0e15-0421-4bcc-d18a-40f920c6eb77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'label'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aug_df = pd.concat([aug_train, aug_test], ignore_index=True)"
      ],
      "metadata": {
        "id": "x6rZJU4q78yI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "tlSRM45E5tcA",
        "outputId": "bb907594-9c1a-4605-a03d-9fdb26afe5ef"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     433564\n",
              "label    433564\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>433564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>433564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aug_df['label'] = aug_df['label'].astype(int)"
      ],
      "metadata": {
        "id": "qzIbLQCT8fVA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_df = aug_df.dropna(how='any')"
      ],
      "metadata": {
        "id": "4vmqR7Kv8niL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "EGAPY49m2CDN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "6ejGqEze8dGB",
        "outputId": "8f28616f-7b43-4fed-9e3e-cf2e7f978ee9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    277981\n",
              "1    155565\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>277981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>155565</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# writing prompts dataset\n"
      ],
      "metadata": {
        "id": "b0zaAcOYtVdU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtIsXkZzDuCJ",
        "outputId": "d124811c-8010-4424-b60e-2ed6799a4e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: abdessamiguebli\n",
            "Your Kaggle Key: 路路路路路路路路路路\n",
            "Dataset URL: https://www.kaggle.com/datasets/ratthachat/writing-prompts\n",
            "Downloading writing-prompts.zip to ./writing-prompts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 370M/370M [00:06<00:00, 62.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/ratthachat/writing-prompts\")\n",
        "# 9aba4703ac130612b1bc4c2d83ed8627\n",
        "#https://www.kaggle.com/datasets/ratthachat/writing-prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02hY3IUBEvq8",
        "outputId": "64aec241-3e9b-40d6-f197-3288dc9f0cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of prompts: 272600\n",
            "Number of stories: 272600\n"
          ]
        }
      ],
      "source": [
        "# Load the prompts and stories\n",
        "with open(\"./writing-prompts/writingPrompts/train.wp_source\", \"r\") as f:\n",
        "    prompts = f.readlines()\n",
        "\n",
        "with open(\"./writing-prompts/writingPrompts/train.wp_target\", \"r\") as f:\n",
        "    stories = f.readlines()\n",
        "\n",
        "print(f\"Number of prompts: {len(prompts)}\")\n",
        "print(f\"Number of stories: {len(stories)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HFPtTHEJFd3N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "human_data = pd.DataFrame({\n",
        "    \"text\": stories,  # Use stories as human-generated text\n",
        "    \"label\": 0        # Human-generated\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge datasets"
      ],
      "metadata": {
        "id": "FvcVdE8FBIqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HKpDMN90Fk9h"
      },
      "outputs": [],
      "source": [
        "# Assuming your RoFT dataset is in a DataFrame `roft_data`\n",
        "df = pd.concat([roft_df, aug_df, human_data], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = aug_df.dropna(how='any')\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "pVogZNltAEBb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fdnZKAQHSj2",
        "outputId": "03d174ff-e82a-483e-f390-426bb7dd73dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    277981\n",
            "1    155565\n",
            "Name: count, dtype: int64\n",
            "Columns in balanced_data:\n",
            "Index(['text', 'label'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df['label'].value_counts())\n",
        "print(\"Columns in balanced_data:\")\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('AiVsHuman.csv')"
      ],
      "metadata": {
        "id": "BTmeNGEuAReT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp ./AiVsHuman.csv /content/drive/MyDrive/Master2/ITFFC/AiVsHuman.csv"
      ],
      "metadata": {
        "id": "ROiF-GenAwJK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model trainning"
      ],
      "metadata": {
        "id": "SVeLgIufBQR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Master2/ITFFC/AiVsHuman.csv ./AiVsHuman.csv"
      ],
      "metadata": {
        "id": "q-KGFttjA-ZM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./AiVsHuman.csv\")\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XLcUf_OBe_5",
        "outputId": "75cf8791-1109-4123-a683-32d2d25e63f4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    277981\n",
            "1    155565\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the dataset by label\n",
        "df_label_0 = df[df['label'] == 0]\n",
        "df_label_1 = df[df['label'] == 1]\n",
        "\n",
        "# Sample 80,000 rows from each label (if there are enough rows)\n",
        "df_label_0_sampled = df_label_0.sample(n=40000, random_state=42)\n",
        "df_label_1_sampled = df_label_1.sample(n=40000, random_state=42)\n",
        "\n",
        "# Concatenate the sampled data back together\n",
        "df_balanced = pd.concat([df_label_0_sampled, df_label_1_sampled])\n",
        "\n",
        "# Shuffle the resulting dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Check the new label distribution\n",
        "print(df_balanced['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txj8daM0EBIQ",
        "outputId": "c71d2121-20ea-4153-d26b-7d326b72696d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1    40000\n",
            "0    40000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_balanced"
      ],
      "metadata": {
        "id": "GOQFIQaFELya"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KlNaGaAcbZK0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r\"\\s*sep\\s*\", \" \", text)  # Remove SEP tokens\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Normalize spaces\n",
        "    return text\n",
        "\n",
        "df[\"text\"] = df[\"text\"].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BqHjpPjKlFCB",
        "outputId": "fe743c1c-653a-4fc3-c552-be6a9e6dda09"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from sklearn.utils import shuffle\\n\\n# Shuffle the dataset\\ndf = shuffle(df, random_state=42)'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''from sklearn.utils import shuffle\n",
        "\n",
        "# Shuffle the dataset\n",
        "df = shuffle(df, random_state=42)'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kCqaWXtJbuPP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train (80%), validation (10%), and test (10%)\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"text\"], df[\"label\"], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
        "    test_texts, test_labels, test_size=0.5, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vqD5hyvRb0mF"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizer\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Tokenize the text\n",
        "# train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\n",
        "# val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=512)\n",
        "# test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-OSiU3HmcEFf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Custom Dataset Class\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "# Create datasets\n",
        "train_dataset = CustomDataset(train_texts, train_labels , tokenizer, max_length=512)\n",
        "val_dataset = CustomDataset(val_texts, val_labels , tokenizer, max_length=512)\n",
        "test_dataset = CustomDataset( test_texts, test_labels , tokenizer, max_length=512)\n",
        "# test_dataset = CustomDataset(test_encodings, test_labels.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gf5yFvZ_cwvn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ],
      "metadata": {
        "id": "E-QG8SPsY3mc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93UcyDCkTge_",
        "outputId": "34d87efc-b5dc-4ea5-fb5f-2ba7c194bbe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Load the pre-trained RoBERTa model\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",        # Save model at the end of each epoch\n",
        "    learning_rate=3e-5,           # Slightly higher learning rate for faster convergence\n",
        "    per_device_train_batch_size=8,  # Reduce batch size to fit GPU memory\n",
        "    per_device_eval_batch_size=8,   # Match evaluation batch size\n",
        "    num_train_epochs=4,           # Reduce the number of epochs\n",
        "    weight_decay=0.01,            # Regularization\n",
        "    logging_dir=\"./logs\",         # Directory for logs\n",
        "    fp16=True,                    # Enable mixed precision for faster training\n",
        "    gradient_accumulation_steps=2, # Accumulate gradients over 2 steps to simulate a larger batch size\n",
        "    save_total_limit=1,           # Keep only the most recent model checkpoint\n",
        "    dataloader_num_workers=4,     # Use multiple workers for data loading\n",
        "\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics  # Add metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "UkQglbB2dLE6",
        "outputId": "02d36dff-9000-4378-b8a6-cadba0b9a0da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16000' max='16000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16000/16000 2:00:47, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.021500</td>\n",
              "      <td>0.010861</td>\n",
              "      <td>0.998125</td>\n",
              "      <td>0.998289</td>\n",
              "      <td>0.998045</td>\n",
              "      <td>0.998167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.012797</td>\n",
              "      <td>0.996875</td>\n",
              "      <td>0.994408</td>\n",
              "      <td>0.999511</td>\n",
              "      <td>0.996953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.015149</td>\n",
              "      <td>0.997375</td>\n",
              "      <td>0.995376</td>\n",
              "      <td>0.999511</td>\n",
              "      <td>0.997439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.012787</td>\n",
              "      <td>0.998375</td>\n",
              "      <td>0.997075</td>\n",
              "      <td>0.999756</td>\n",
              "      <td>0.998414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=16000, training_loss=0.01853624709136784, metrics={'train_runtime': 7249.403, 'train_samples_per_second': 35.313, 'train_steps_per_second': 2.207, 'total_flos': 6.735643017216e+16, 'train_loss': 0.01853624709136784, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHtprzwG6Pr6",
        "outputId": "927248db-441f-416c-dad7-4e37ac0ab42f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Master2/ITFFC/first_80k_4ep_model/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Master2/ITFFC/first_80k_4ep_model/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Master2/ITFFC/first_80k_4ep_model/vocab.json',\n",
              " '/content/drive/MyDrive/Master2/ITFFC/first_80k_4ep_model/merges.txt',\n",
              " '/content/drive/MyDrive/Master2/ITFFC/first_80k_4ep_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Save the model\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Master2/ITFFC/first_80k_4ep_model\")\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Master2/ITFFC/first_80k_4ep_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "metrics = trainer.evaluate()\n",
        "print(\"Validation Metrics:\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "36DR3U0z3oA6",
        "outputId": "91109fe2-483d-4477-de65-46907da0d24e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 01:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'eval_loss': 0.012787416577339172, 'eval_accuracy': 0.998375, 'eval_precision': 0.997075310748233, 'eval_recall': 0.9997556207233627, 'eval_f1': 0.9984136668700427, 'eval_runtime': 72.3077, 'eval_samples_per_second': 110.638, 'eval_steps_per_second': 13.83, 'epoch': 4.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predictions = trainer.predict(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "wg5RTp7Lj8WK",
        "outputId": "45ad8730-ce86-4f41-919f-b9fde0d0fb47"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicted labels\n",
        "predicted_labels = predictions.predictions.argmax(-1)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(test_labels, predicted_labels, target_names=[\"Human-Generated\", \"AI-Generated\"])\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxagiVd14cXG",
        "outputId": "1a56c1f7-f0b1-4c7c-c1e3-4018c0acd671"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Human-Generated       1.00      1.00      1.00      4008\n",
            "   AI-Generated       1.00      1.00      1.00      3992\n",
            "\n",
            "       accuracy                           1.00      8000\n",
            "      macro avg       1.00      1.00      1.00      8000\n",
            "   weighted avg       1.00      1.00      1.00      8000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using the model"
      ],
      "metadata": {
        "id": "XbQiZsf85lN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add explainability (token and sentence level)\n",
        "def explain(text):\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    # Perform inference with attention outputs\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_attentions=True)\n",
        "        attentions = outputs.attentions  # Attention scores\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Predicted class\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "    labels = [\"Human-Generated\", \"AI-Generated\"]\n",
        "\n",
        "    # Token-level explanation\n",
        "    attention_scores = attentions[0][0].mean(dim=0).mean(dim=0)  # Average over heads\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    token_attention = list(zip(tokens, attention_scores.tolist()))\n",
        "\n",
        "    # Sentence-level explanation\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentence_scores = []\n",
        "    for sentence in sentences:\n",
        "        sentence_inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**sentence_inputs, output_attentions=True)\n",
        "            attentions = outputs.attentions[0]\n",
        "            attention_scores = attentions.mean(dim=1).mean(dim=0)\n",
        "            sentence_scores.append(attention_scores.mean().item())\n",
        "\n",
        "    return {\n",
        "        \"predicted_label\": labels[predicted_class],\n",
        "        \"token_explanations\": token_attention,\n",
        "        \"sentence_explanations\": list(zip(sentences, sentence_scores))\n",
        "    }\n"
      ],
      "metadata": {
        "id": "SGzgSr1jZXdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JmTirMqTYV-"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/Master2/ITFFC/third_model\"\n",
        "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-lZsBd6eNkW"
      },
      "outputs": [],
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Prepare the test dataset\n",
        "texts = test_dataset[\"text\"]  # Adjust key based on your test dataset\n",
        "true_labels = test_dataset[\"label\"]\n",
        "\n",
        "# Tokenize the test data\n",
        "inputs = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "# Get predicted labels\n",
        "predicted_labels = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "# Calculate metrics\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNpkE3fd3IBs",
        "outputId": "771fb0b2-b389-42ba-8f34-94544eac44ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted label: Human-Generated\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Set the device (use GPU if available, else fallback to CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "model = model.to(device)\n",
        "\n",
        "# Input text\n",
        "text = \"\"\"\n",
        "As the sun dipped below the horizon, painting the sky in hues of orange and pink, the air grew cooler, carrying the faint scent of blooming jasmine. Emma paused on the cobblestone path, letting the beauty of the moment wash over her. It wasnt often that life slowed down enough to let her notice these small, fleeting wonders.\n",
        "\n",
        "In the distance, the laughter of children echoed, mingling with the rustle of leaves in the evening breeze. A sense of peace enveloped her, a stark contrast to the chaos of the day. Deadlines, meetings, and the relentless pace of her work had left her drained. But here, in the quiet of this small park, she felt a renewed sense of clarity.\n",
        "\n",
        "She took a deep breath, her shoulders relaxing. Maybe it wasnt about finding balance, she thought. Maybe it was about embracing the imbalance, finding moments like these to anchor her, however brief they might be.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Move the input tensors to the same device as the model\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# Perform inference\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "# Get the predicted class\n",
        "predicted_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "# Interpret the output\n",
        "labels = [\"Human-Generated\", \"AI-Generated\"]\n",
        "print(f\"Predicted label: {labels[predicted_class]}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "16zQneXzHab7n04GHmhrfRaWDYNIvzcDd",
      "authorship_tag": "ABX9TyNMZqFzgO4NnGdpt6PbCoMr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}